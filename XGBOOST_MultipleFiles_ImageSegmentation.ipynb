{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# XGBoost Example\n",
    "# I acknowledge \"Sreenivas Bhattiprolu\" ( https://github.com/bnsreenu/python_for_microscopists),\n",
    "# the based code for XGBoost has been taken from his git \n",
    "# I added two main things:\n",
    "#     -The posibility to load several Images as training\n",
    "#     -A set of features including: gamma constrasting, H&E Stainnig, range color\n",
    "# Code is structed to be used with randomForest, SVM or XGBoost\n",
    "import glob\n",
    "import pickle\n",
    "path = \"C:/ImageFolder/*.*\"\n",
    "fileArra=[]\n",
    "for file in glob.glob(path):\n",
    "    print(file) \n",
    "    fileArra.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "from skimage.color import (separate_stains, combine_stains,hdx_from_rgb, rgb_from_hdx,rgb_from_fgx,fgx_from_rgb)\n",
    "from skimage.color import (rgb_from_bex,bex_from_rgb)\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import functools\n",
    "import numpy as np\n",
    "from warnings import warn\n",
    "from scipy import linalg\n",
    "from skimage.util import dtype, dtype_limits\n",
    "from skimage import exposure\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "def _prepare_colorarray(arr, force_copy=False):\n",
    "    \"\"\"Check the shape of the array and convert it to\n",
    "    floating point representation.\n",
    "    \"\"\"\n",
    "    arr = np.asanyarray(arr)\n",
    "\n",
    "    if arr.shape[-1] != 3:\n",
    "        raise ValueError(\"Input array must have a shape == (..., 3)), \"\n",
    "                         f\"got {arr.shape}\")\n",
    "\n",
    "    return dtype.img_as_float(arr, force_copy=force_copy)\n",
    "\n",
    "def separate_StainsS(ihc,conv_matrix):\n",
    "    rgb = _prepare_colorarray(ihc, force_copy=True)\n",
    "    np.maximum(rgb, 1E-6, out=rgb)  # avoiding log artifacts\n",
    "    log_adjust = np.log(1E-6)  # used to compensate the sum above\n",
    "    stains = (np.log(rgb) / log_adjust) @ conv_matrix\n",
    "    np.maximum(stains, 0, out=stains)\n",
    "    return stains\n",
    "\n",
    "def combine_stainsA(stains, conv_matrix):\n",
    "    log_adjust = -np.log(1E-6)\n",
    "    log_rgb = -(stains * log_adjust) @ conv_matrix\n",
    "    rgb = np.exp(log_rgb)\n",
    "    return np.clip(rgb, a_min=0, a_max=1)\n",
    "\n",
    "def histCalculation(ihc):\n",
    "    ihc = cv.cvtColor(ihc, cv.COLOR_BGR2RGB)\n",
    "    conv= bex_from_rgb\n",
    "    stains= separate_StainsS(ihc,conv)\n",
    "    ihc_hdx= stains\n",
    "    # Create an RGB image for each of the stains\n",
    "    null = np.zeros_like(ihc_hdx[:, :, 0])\n",
    "    conv_Inv=rgb_from_bex \n",
    "    ihc_e = combine_stainsA(np.stack((null,ihc_hdx[:, :, 1], null), axis=-1), conv_Inv)\n",
    "    newImag= np.array(ihc_e*255, dtype=\"uint8\")\n",
    "    outImagHist=cv.cvtColor(newImag, cv.COLOR_BGR2GRAY)\n",
    "    return outImagHist\n",
    "\n",
    "# Range Threshold\n",
    "\n",
    "def rangeFilter(imHSV):\n",
    "    h1=round(190/360*180)\n",
    "    h2=round(345/360*180)\n",
    "    s1=round(10/100*255)\n",
    "    s2=round(100/100*180)\n",
    "    v1=round(20/100*255)\n",
    "    v2=255\n",
    "    print(h1,s1,v1,\"--\",h2,s2,v2)\n",
    "    lower_red = np.array([h1,s1,v1])\n",
    "    upper_red = np.array([h2,s2,v2])\n",
    "    mask1 = cv.inRange(imHSV, lower_red, upper_red)\n",
    "    return mask1\n",
    "\n",
    "def gammaContrastFilter(imRGB,imHSV):\n",
    "    gamma_corrected = exposure.adjust_gamma(imRGB, 10)\n",
    "    imgInput= gamma_corrected\n",
    "    imgGray = cv2.cvtColor(imgInput, cv2.COLOR_BGR2GRAY) \n",
    "    imagem = cv2.bitwise_not(imgGray)\n",
    "    a,thinned= cv.threshold(imagem, 100, 255, cv.THRESH_BINARY)\n",
    "    lower_red = np.array([50,20,1])\n",
    "    upper_red = np.array([80,255,240])\n",
    "    mask = cv.inRange(imHSV, lower_red, upper_red)\n",
    "    mask=cv.dilate(mask, None)\n",
    "    mask=cv.dilate(mask, None)\n",
    "    image3 = cv.subtract(thinned, mask)\n",
    "    return image3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 26 51 -- 172 180 255\n",
      "95 26 51 -- 172 180 255\n",
      "95 26 51 -- 172 180 255\n",
      "95 26 51 -- 172 180 255\n",
      "95 26 51 -- 172 180 255\n",
      "95 26 51 -- 172 180 255\n",
      "95 26 51 -- 172 180 255\n",
      "95 26 51 -- 172 180 255\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "imagArra=[]\n",
    "imagGreyArra=[]\n",
    "imgHueFull= np.array([])\n",
    "imgSaturationFull=np.array([])\n",
    "imgValueFull=np.array([])\n",
    "imgGreyFull=np.array([])\n",
    "imgHistFull=np.array([])\n",
    "imgRangFull=np.array([])\n",
    "imgGammFull=np.array([])\n",
    "for data in fileArra:\n",
    "    imgInput = cv2.imread(data)\n",
    "    img = cv2.cvtColor(imgInput, cv2.COLOR_BGR2HSV) \n",
    "    img2= cv2.cvtColor(imgInput, cv2.COLOR_BGR2GRAY)\n",
    "    imagArra.append(img)\n",
    "    imagGreyArra.append(img2)\n",
    "    img_hue= img[:,:,0]\n",
    "    img_saturation= img[:,:,1]\n",
    "    img_value= img[:,:,2]\n",
    "    img2_hue = img_hue.reshape(-1)\n",
    "    img2_saturation = img_saturation.reshape(-1)\n",
    "    img2_value = img_value.reshape(-1)\n",
    "    img2_grey = img2.reshape(-1)\n",
    "    img_hist= histCalculation(imgInput)\n",
    "    img2_hist= img_hist.reshape(-1)\n",
    "    img_Range= rangeFilter(img)\n",
    "    img2_Range=  img_Range.reshape(-1)\n",
    "    img_Gamma= gammaContrastFilter(imgInput,img)\n",
    "    img2_Gamma= img_Gamma.reshape(-1)\n",
    "    imgHueFull=np.concatenate((imgHueFull,img2_hue),axis=None)\n",
    "    imgSaturationFull=np.concatenate((imgSaturationFull,img2_saturation),axis=None)\n",
    "    imgValueFull=np.concatenate((imgValueFull,img2_value),axis=None)\n",
    "    imgGreyFull=np.concatenate((imgGreyFull,img2_grey),axis=None)\n",
    "    imgHistFull=np.concatenate((imgHistFull,img2_hist),axis=None)\n",
    "    imgRangFull=np.concatenate((imgRangFull,img2_Range),axis=None)\n",
    "    imgGammFull=np.concatenate((imgGammFull,img2_Gamma),axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple images can be used for training. For that, you need to concatenate the data\n",
    "#Save original image pixels into a data frame. This is our Feature #1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Original Image Hue'] = imgHueFull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Original Image Saturation'] = imgSaturationFull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Original Image Value'] = imgValueFull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Original Image'] = imgGreyFull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Original Image Hist'] = imgHistFull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Original Image Range'] = imgRangFull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Original Image Gamma'] = imgGammFull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Image Hue</th>\n",
       "      <th>Original Image Saturation</th>\n",
       "      <th>Original Image Value</th>\n",
       "      <th>Original Image</th>\n",
       "      <th>Original Image Hist</th>\n",
       "      <th>Original Image Range</th>\n",
       "      <th>Original Image Gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290370</th>\n",
       "      <td>35.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290371</th>\n",
       "      <td>51.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290372</th>\n",
       "      <td>48.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290373</th>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290374</th>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1290375 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Original Image Hue  Original Image Saturation  Original Image Value  \\\n",
       "0                      62.0                       14.0                 255.0   \n",
       "1                      62.0                       16.0                 255.0   \n",
       "2                      62.0                       15.0                 255.0   \n",
       "3                      62.0                       14.0                 255.0   \n",
       "4                      62.0                       14.0                 251.0   \n",
       "...                     ...                        ...                   ...   \n",
       "1290370                35.0                       11.0                 249.0   \n",
       "1290371                51.0                        7.0                 243.0   \n",
       "1290372                48.0                        5.0                 255.0   \n",
       "1290373                36.0                        5.0                 255.0   \n",
       "1290374                24.0                        5.0                 254.0   \n",
       "\n",
       "         Original Image  Original Image Hist  Original Image Range  \\\n",
       "0                 249.0                255.0                   0.0   \n",
       "1                 249.0                255.0                   0.0   \n",
       "2                 249.0                255.0                   0.0   \n",
       "3                 249.0                255.0                   0.0   \n",
       "4                 245.0                255.0                   0.0   \n",
       "...                 ...                  ...                   ...   \n",
       "1290370           247.0                251.0                   0.0   \n",
       "1290371           241.0                251.0                   0.0   \n",
       "1290372           254.0                255.0                   0.0   \n",
       "1290373           254.0                254.0                   0.0   \n",
       "1290374           253.0                253.0                   0.0   \n",
       "\n",
       "         Original Image Gamma  \n",
       "0                         0.0  \n",
       "1                         0.0  \n",
       "2                         0.0  \n",
       "3                         0.0  \n",
       "4                         0.0  \n",
       "...                       ...  \n",
       "1290370                   0.0  \n",
       "1290371                 255.0  \n",
       "1290372                   0.0  \n",
       "1290373                   0.0  \n",
       "1290374                   0.0  \n",
       "\n",
       "[1290375 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage as nd\n",
    "from skimage.filters import roberts, sobel, scharr, prewitt\n",
    "\n",
    "edges1Full= np.array([])\n",
    "edge_roberts1Full = np.array([])\n",
    "edge_sobel1Full= np.array([])\n",
    "edge_scharr1Full= np.array([])\n",
    "edge_prewitt1Full= np.array([])\n",
    "gaussian_img1Full= np.array([])\n",
    "gaussian_img3Full= np.array([])\n",
    "median_img1Full= np.array([])\n",
    "variance_img1Full= np.array([])\n",
    "\n",
    "\n",
    "for img2 in imagGreyArra:\n",
    "    #CANNY EDGE\n",
    "    edges = cv2.Canny(img2, 100,200)   #Image, min and max values\n",
    "    edges1 = edges.reshape(-1)\n",
    "    edges1Full= np.concatenate((edges1Full,edges1),axis=None)\n",
    "\n",
    "    #ROBERTS EDGE\n",
    "    edge_roberts = roberts(img2)\n",
    "    edge_roberts1 = edge_roberts.reshape(-1)\n",
    "    edge_roberts1Full= np.concatenate((edge_roberts1Full,edge_roberts1),axis=None)\n",
    "\n",
    "    #SOBEL\n",
    "    edge_sobel = sobel(img2)\n",
    "    edge_sobel1 = edge_sobel.reshape(-1)\n",
    "    edge_sobel1Full= np.concatenate((edge_sobel1Full,edge_sobel1),axis=None)\n",
    "    #SCHARR\n",
    "    edge_scharr = scharr(img2)\n",
    "    edge_scharr1 = edge_scharr.reshape(-1)\n",
    "    edge_scharr1Full= np.concatenate((edge_scharr1Full,edge_scharr1),axis=None)\n",
    "    #PREWITT\n",
    "    edge_prewitt = prewitt(img2)\n",
    "    edge_prewitt1 = edge_prewitt.reshape(-1)\n",
    "    edge_prewitt1Full= np.concatenate((edge_prewitt1Full,edge_prewitt1),axis=None)\n",
    "    #GAUSSIAN with sigma=3\n",
    "    gaussian_img = nd.gaussian_filter(img2, sigma=3)\n",
    "    gaussian_img1 = gaussian_img.reshape(-1)\n",
    "    gaussian_img1Full= np.concatenate((gaussian_img1Full,gaussian_img1),axis=None)\n",
    "    #GAUSSIAN with sigma=7\n",
    "    gaussian_img2 = nd.gaussian_filter(img2, sigma=7)\n",
    "    gaussian_img3 = gaussian_img2.reshape(-1)\n",
    "    gaussian_img3Full= np.concatenate((gaussian_img3Full,gaussian_img3),axis=None)\n",
    "    #MEDIAN with sigma=3\n",
    "    median_img = nd.median_filter(img2, size=3)\n",
    "    median_img1 = median_img.reshape(-1)\n",
    "    median_img1Full= np.concatenate((median_img1Full,median_img1),axis=None)\n",
    "    #VARIANCE with size=3\n",
    "    variance_img = nd.generic_filter(img2, np.var, size=3)\n",
    "    variance_img1 = variance_img.reshape(-1)\n",
    "    variance_img1Full= np.concatenate((variance_img1Full,variance_img1),axis=None)\n",
    "    \n",
    "df['Canny Edge'] = edges1Full #Add column to original dataframe\n",
    "df['Roberts'] = edge_roberts1Full\n",
    "df['Sobel'] = edge_sobel1Full\n",
    "df['Scharr'] = edge_scharr1Full\n",
    "df['Prewitt'] = edge_prewitt1Full\n",
    "df['Gaussian s3'] = gaussian_img1Full\n",
    "df['Gaussian s7'] = gaussian_img3Full\n",
    "df['Median s3'] = median_img1Full\n",
    "df['Variance s3'] = variance_img1Full  #Add column to original dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this run the feature below where excluded, uncomment then to explorer those features\n",
    "# print(edges1Full.shape,edge_roberts1Full.shape)\n",
    "# df['Canny Edge'] = edges1Full #Add column to original dataframe\n",
    "# df['Roberts'] = edge_roberts1Full\n",
    "# df['Sobel'] = edge_sobel1Full\n",
    "# df['Scharr'] = edge_scharr1Full\n",
    "# df['Prewitt'] = edge_prewitt1Full\n",
    "# df['Gaussian s3'] = gaussian_img1Full\n",
    "# df['Gaussian s7'] = gaussian_img3Full\n",
    "# df['Median s3'] = median_img1Full\n",
    "# df['Variance s3'] = variance_img1Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Image Hue</th>\n",
       "      <th>Original Image Saturation</th>\n",
       "      <th>Original Image Value</th>\n",
       "      <th>Original Image</th>\n",
       "      <th>Original Image Hist</th>\n",
       "      <th>Original Image Range</th>\n",
       "      <th>Original Image Gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290370</th>\n",
       "      <td>35.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290371</th>\n",
       "      <td>51.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290372</th>\n",
       "      <td>48.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290373</th>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290374</th>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1290375 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Original Image Hue  Original Image Saturation  Original Image Value  \\\n",
       "0                      62.0                       14.0                 255.0   \n",
       "1                      62.0                       16.0                 255.0   \n",
       "2                      62.0                       15.0                 255.0   \n",
       "3                      62.0                       14.0                 255.0   \n",
       "4                      62.0                       14.0                 251.0   \n",
       "...                     ...                        ...                   ...   \n",
       "1290370                35.0                       11.0                 249.0   \n",
       "1290371                51.0                        7.0                 243.0   \n",
       "1290372                48.0                        5.0                 255.0   \n",
       "1290373                36.0                        5.0                 255.0   \n",
       "1290374                24.0                        5.0                 254.0   \n",
       "\n",
       "         Original Image  Original Image Hist  Original Image Range  \\\n",
       "0                 249.0                255.0                   0.0   \n",
       "1                 249.0                255.0                   0.0   \n",
       "2                 249.0                255.0                   0.0   \n",
       "3                 249.0                255.0                   0.0   \n",
       "4                 245.0                255.0                   0.0   \n",
       "...                 ...                  ...                   ...   \n",
       "1290370           247.0                251.0                   0.0   \n",
       "1290371           241.0                251.0                   0.0   \n",
       "1290372           254.0                255.0                   0.0   \n",
       "1290373           254.0                254.0                   0.0   \n",
       "1290374           253.0                253.0                   0.0   \n",
       "\n",
       "         Original Image Gamma  \n",
       "0                         0.0  \n",
       "1                         0.0  \n",
       "2                         0.0  \n",
       "3                         0.0  \n",
       "4                         0.0  \n",
       "...                       ...  \n",
       "1290370                   0.0  \n",
       "1290371                 255.0  \n",
       "1290372                   0.0  \n",
       "1290373                   0.0  \n",
       "1290374                   0.0  \n",
       "\n",
       "[1290375 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "locationLabels= \"C:/Labels/RF_Clasified\"\n",
    "dataLabel= location+\"/BluePrint40007.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data with the labels\n",
    "labeled_img1Full= np.array([])\n",
    "for data in fileArra:\n",
    "#     print(data)\n",
    "    splitA=data.split(\"Clasification\")[1]\n",
    "    splitB=splitA.split(\"\\\\\")[1]\n",
    "    name= splitB.split(\".\")[0]\n",
    "#     print(name)\n",
    "    clasName=name+\"_clasified.png\"\n",
    "    dataLabel=locationLabels+\"/\"+clasName\n",
    "    print(dataLabel)\n",
    "    #Now, add a column in the data frame for the Labels\n",
    "    #For this, we need to import the labeled image\n",
    "    labeled_img = cv2.imread(dataLabel)\n",
    "    #Remember that you can load an image with partial labels \n",
    "    #But, drop the rows with unlabeled data\n",
    "\n",
    "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_BGR2GRAY)\n",
    "    labeled_img1 = labeled_img.reshape(-1)\n",
    "    labeled_img1Full=np.concatenate((labeled_img1Full,labeled_img1),axis=None)\n",
    "df['Labels'] = labeled_img1Full\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################                \n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "\n",
    "#Define the dependent variable that needs to be predicted (labels)\n",
    "Y = df[\"Labels\"].values\n",
    "\n",
    "#Define the independent variables\n",
    "X = df.drop(labels = [\"Labels\"], axis=1) \n",
    "\n",
    "#Split data into train and test to verify accuracy after fitting the model. \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=20)\n",
    "\n",
    "\n",
    "# Import the model we are using\n",
    "#For classification we use RandomForestClassifier.\n",
    "#Here you can change between RandomForest or XGBoost. \n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# Instantiate model with n number of decision trees\n",
    "model = xgb.XGBClassifier()\n",
    "# model = RandomForestClassifier(n_estimators = 200, random_state = 42,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:23] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "# Train the Linear SVM to compare against Random Forest\n",
    "#SVM will be slower than Random Forest. \n",
    "#Make sure to comment out Fetaure importances lines of code as it does not apply to SVM.\n",
    "#from sklearn.svm import LinearSVC\n",
    "#model = LinearSVC(max_iter=100)  #Default of 100 is not converging\n",
    "\n",
    "# Train the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# verify number of trees used. If not defined above. \n",
    "#print('Number of Trees used : ', model.n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line is for RandomForest\n",
    "# print('Number of Trees used : ', model.n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 8: TESTING THE MODEL BY PREDICTING ON TEST DATA\n",
    "#AND CALCULATE THE ACCURACY SCORE\n",
    "#First test prediction on the training data itself. SHould be good. \n",
    "prediction_test_train = model.predict(X_train)\n",
    "\n",
    "#Test prediction on testing data. \n",
    "prediction_test = model.predict(X_test)\n",
    "\n",
    "#.predict just takes the .predict_proba output and changes everything \n",
    "#to 0 below a certain threshold (usually 0.5) respectively to 1 above that threshold.\n",
    "#In this example we have 4 labels, so the probabilities will for each label stored separately. \n",
    "# \n",
    "#prediction_prob_test = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data =  0.9959998708385805\n",
      "Accuracy =  0.99515644676935\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Let us check the accuracy on test data\n",
    "from sklearn import metrics\n",
    "#Print the prediction accuracy\n",
    "\n",
    "#First check the accuracy on training data. This will be higher than test data prediction accuracy.\n",
    "print (\"Accuracy on training data = \", metrics.accuracy_score(y_train, prediction_test_train))\n",
    "#Check accuracy on test dataset. If this is too low compared to train it indicates overfitting on training data.\n",
    "print (\"Accuracy = \", metrics.accuracy_score(y_test, prediction_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#This part commented out for SVM testing. Uncomment for random forest. \n",
    "#One amazing feature of Random forest and XGBoost is that it provides us info on feature importances\n",
    "# Get numerical feature importances\n",
    "importances = list(model.feature_importances_)\n",
    "\n",
    "#Let us print them into a nice format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3153182,\n",
       " 0.056979544,\n",
       " 0.09045442,\n",
       " 0.082824335,\n",
       " 0.25068504,\n",
       " 0.16164985,\n",
       " 0.042088557]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Image Hue           0.315318\n",
      "Original Image Hist          0.250685\n",
      "Original Image Range         0.161650\n",
      "Original Image Value         0.090454\n",
      "Original Image               0.082824\n",
      "Original Image Saturation    0.056980\n",
      "Original Image Gamma         0.042089\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_list = list(X.columns)\n",
    "feature_imp = pd.Series(model.feature_importances_,index=feature_list).sort_values(ascending=False)\n",
    "print(feature_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"C:/SavedModel\"\n",
    "dataSaveModel= location+\"/RainRFModel08OCT2021_1108.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "noContribution= [1,2,13,9,10,14,15,16,17,18,25,26,27,19] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#Save the trained model as pickle string to disk for future use\n",
    "filename = \"bM_XGBOOST_Explore_RainIRHSVMultiHistRange08OCT\"\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "#To test the model on future datasets\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.predict(X)\n",
    "\n",
    "# segmented = result.reshape((img2.shape))\n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.imshow(segmented, cmap ='jet')\n",
    "# plt.imsave('bM_RF_Explore_RainIRHSV.jpg', segmented, cmap ='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
